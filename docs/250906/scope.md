# スコープ定義書: AIレビューパネル (ハッカソンMVP)

## 1. プロジェクトの目的とゴール

本プロジェクトの目的は、ハッカソン期間内に「AIレビューパネル」のMVP(Minimum Viable Product)を開発し、その核心的な価値提案（PdMのPRDレビューにおける認知負荷の軽減と仕様品質の向上）を実証することである。

最終的なゴールは、以下の体験を実現する、動作可能なWebアプリケーションを完成させることである。
- ユーザーがPRDテキストを入力すると、複数の専門的視点を持つAIがレビューを実行する。
- ユーザーは、AIが提示する最も重要な論点から一つずつ、対話形式で仕様を深掘り・改善できる。
- レビュー結果を、チームに共有可能なサマリーとして出力できる。

## 2. スコープに含むこと (In-Scope)

ハッカソンMVPで実装する機能・要件は以下に限定される。

### 2.1 コア機能・体験
- **PRDインプット:**
    - テキストを直接貼り付けられる単一のWebページ。
- **AIレビュー実行:**
    - バックエンドで、定義済みのマルチエージェント（オーケストレーター、スペシャリスト）がレビューを実行する。
- **フォーカスモード体験:**
    - レビュー結果を、優先度順に**一つずつカード形式で**表示するUI。
- **対話による深掘り:**
    - 各論点カード内で、AIとチャット形式で追加の質問ができる。
- **AIによる修正案提案:**
    - AIがPRDの具体的な修正文を提案する機能。
- **ワンクリック修正適用:**
    - 提案された修正案を、ボタン一つでPRD原文に自動反映する機能。
- **結果の共有:**
    - レビュー結果のサマリーを、閲覧専用のユニークなURLで共有できる。

### 2.2 技術要素
- **AIバックエンド:**
    - PythonおよびGoogle ADKを用いたマルチエージェント・アーキテクチャの実装。
- **プロンプト管理:**
    - TOML形式のファイルで、各エージェントのプロンプトを一元管理する。
- **テスト:**
    - `adk web` を活用し、オーケストレーターエージェントの統合テストを実施する。

## 3. スコープに含まないこと (Out-of-Scope)

リソースを集中させるため、以下の機能はハッカソンMVPのスコープ外とする。

### 3.1 機能・体験
- **ユーザーアカウント関連機能:**
    - ログイン、ユーザー登録、プロジェクトの保存・管理機能は一切実装しない。
- **フォーカスモード以外のUI:**
    - 指摘事項を一覧表示する「インボックス・トリアージモデル」や、PRD原文にコメントを付ける「インタラクティブ・ドキュメントモデル」は実装しない。
- **高度な設定機能:**
    - ユーザーがレビューに参加するAIエージェントをカスタマイズする機能。
- **外部ツール連携:**
    - Jira, Figma, Slack等との連携機能。

### 3.2 技術要素
- **AIエージェントの高度な能力:**
    - エージェントが外部情報（例: コードリポジトリ）を参照するためのツール利用。
    - 複数のレビューセッションをまたいで記憶を維持する機能。
- **永続的なデータストレージ:**
    - レビュー内容はセッション内でのみ保持し、複雑なデータベースは構築しない。（インメモリまたは一時ファイルで代替）
- **多言語対応:**
    - PRDおよびUIは日本語のみを対象とする。

## 4. 成果物

- 動作するWebアプリケーションのデモ環境
- 上記スコープを実装したソースコード一式
- プロダクトドキュメント (`prd.md`, `usm.md`, `architecture.md`, `scope.md`)

## 5. 前提条件と制約事項

- **前提条件:**
    - LLM API（例: Gemini API）が利用可能であること。
- **制約事項:**
    - 開発期間はハッカソンの期間内（3週間）とする。
    - 開発リソースは参加するチームメンバーに限られる。

---

# WBS (Work Breakdown Structure) - 3週間計画

3週間の開発期間を1週間ごとのスプリントに区切り、以下のマイルストーン達成を目指す。アーキテクチャ設計書で定義した「段階的な開発・テスト戦略」に基づき、タスクを分解する。

---

### **Week 1: AIコアエンジンの完成とAPIコントラクトの確定**
**目標:** AIが価値あるレビューを生成できることを技術的に証明し、フロントエンドチームが開発を開始できるモックAPIを完成させる。

-   [ ] **1. 開発環境のセットアップ**
    -   [x] 1.1 Gitリポジトリの作成とブランチ戦略の合意
    -   [ ] 1.2 Python (`uv`) / Node.js (`npm`) 開発環境のセットアップ
    -   [ ] 1.3 依存パッケージ定義 (`pyproject.toml`, `package.json`)
    -   [x] 1.4 LLM APIキーの共有と `.env` ファイルでの管理
-   [ ] **2. AIコアエンジンの開発と単体テスト (ADK)**
    -   [x] 2.1 Pydanticモデルの定義 (`adk_app/schemas.py`)
        -   **Done:** `IssueItem`, `SpecialistOutput`, `FinalIssue`, `ReviewSessionForTool` の4つのPydanticモデルがコードとして定義されていること。
    -   [x] 2.2 プロンプトの設計 (`prompts/agents.toml`) (v1)
        -   **Done:** `engineer`, `ux`, `qa`, `pm` の4つの専門家エージェントそれぞれについて、`system`プロンプトと`task`プロンプトが記述されていること。
    -   [ ] 2.3 `SpecialistAgent` の実装と単体テスト
        -   [x] 2.3.1 `adk_app/agents.py` に `SpecialistAgent` クラスを定義する。
            -   **Done:** ADKの`Agent`を継承し、`__init__`と非同期`__call__`メソッドを持つクラスが実装されていること。
        -   [ ] 2.3.2 `tests/test_specialist_agent.py` という単体テストスクリプトを作成する。
            -   **Done:** スクリプトが作成され、内部で`SpecialistAgent`をインスタンス化し、テスト用のPRDテキストを渡して呼び出すコードが書かれていること。
        -   [ ] 2.3.3 テストスクリプトを実行し、`SpecialistAgent`が期待通りの形式で出力することを検証する。
            -   **Done:** スクリプトを実行すると、`SpecialistAgent`が`SpecialistOutput` Pydanticモデルに準拠したJSONを出力し、テストがエラーなく成功すること。
    -   [ ] 2.4 `structure_review_results` ツールの実装と単体テスト
        -   [x] 2.4.1 `adk_app/tools.py` に `structure_review_results` 非同期関数を定義する。
            -   **Done:** 関数が定義され、複数の`SpecialistAgent`を`asyncio.gather`で並行実行するロジックが実装されていること。
        -   [ ] 2.4.2 `tests/test_review_tool.py` という単体テストスクリプトを作成する。
            -   **Done:** スクリプトが作成され、`structure_review_results`関数を呼び出し、返り値を検証するコードが書かれていること。
        -   [ ] 2.4.3 テストスクリプトを実行し、ツールが期待通りの形式で出力することを検証する。
            -   **Done:** スクリプトを実行すると、ツールが`ReviewSessionForTool` Pydanticモデルに準拠したJSONを出力し、`priority`順にソートされていることが確認でき、テストが成功すること。
    -   [ ] 2.5 `OrchestratorAgent` の実装と統合テスト
        -   [x] 2.5.1 `adk_app/agents.py` に `OrchestratorAgent` クラスを定義する。
            -   **Done:** `structure_review_results`ツールを登録したADKエージェントが実装されていること。
        -   [ ] 2.5.2 `adk web --agent_path adk_app/agents.py --agent_name OrchestratorAgent` コマンドを実行し、テストUIを起動する。
            -   **Done:** コマンドが成功し、ブラウザでADKのテスト用Web UIが表示されること。
        -   [ ] 2.5.3 Web UIからテスト用のPRDテキストを送信し、最終的なレビュー結果がJSONとして表示されることを確認する。
            -   **Done:** `structure_review_results`ツールが呼び出されたログが出力され、最終的な`ReviewSessionForTool`形式のJSONがUI上に表示されること。
-   [ ] **3. Web APIのモック実装 (FastAPI)**
    -   [ ] 3.1 FastAPIプロジェクトの基本セットアップとディレクトリ構成の決定 (`app/`以下)
    -   [ ] 3.2 `architecture.md`のAPI仕様に基づき、全5エンドポイントのI/Oを`app/schemas.py`で定義
    -   [ ] 3.3 全エンドポイントを、AIを呼ばずにダミーのJSONデータを返すモックとして実装
    -   [ ] 3.4 Next.jsからのアクセスを許可するためのCORS設定

---

### **Week 2: APIの本実装とフロントエンドの基本フロー完成**
**目標:** フロントエンドとバックエンドを結合し、「フォーカスモード」によるPRDレビューの一連の体験がWebアプリケーション上で完結する。

-   [ ] **4. APIの本実装とAIエンジンの結合**
    -   [ ] 4.1 FastAPIの`lifespan`と依存性注入のセットアップ
        -   **Done:** `app/lifespan.py`, `app/dependencies.py`が作成され、`app/main.py`に組み込まれていること。
    -   [ ] 4.2 `run_ai_review_service`を実装し、`POST /reviews`を本実装に差し替え
        -   **Done:** `app/services.py`にADKの`Runner`を呼び出すロジックが実装され、APIがそれを非同期タスクとして実行できること。
    -   [ ] 4.3 対話API (`/dialog`) の実装
        -   **Done:** `architecture.md`の設計通り、担当AI特定と動的プロンプト生成ロジックが実装され、`SpecialistAgent`を呼び出して応答を返せること。
    -   [ ] 4.4 提案・適用API (`/suggest`, `/apply_suggestion`) の実装
        -   **Done:** 各エンドポイントがそれぞれの責務（提案生成、PRD原文の更新）を果たすロジックが実装されていること。
    -   [ ] 4.5 APIの自動E2Eテストの実装
        -   **Done:** `pytest`+`httpx`で、レビュー開始から完了までのAPIフローを検証するテストコードが実装され、CIで成功すること。
-   [ ] **5. フロントエンド開発 (Next.js)**
    -   [ ] 5.1 Next.js (App Router, TypeScript, Tailwind CSS) でのプロジェクトセットアップ
        -   **Done:** `create-next-app`が完了し、`tailwind.config.js`等の設定ファイルが正しく構成されていること。
    -   [ ] 5.2 APIクライアントモジュールとポーリング処理の実装
        -   **Done:** `fetch`等をラップしたAPI呼び出し関数群と、`useSWR`や`React Query`等を用いたポーリング機構が実装されていること。
    -   [ ] 5.3 状態管理ライブラリの導入と実装
        -   **Done:** `Jotai`や`Zustand`等が導入され、レビューセッションのグローバルな状態（`issues`リスト、現在の`issue`インデックス等）が管理されていること。
    -   [ ] 5.4 UIコンポーネント実装
        -   **Done:** `Storybook`等で、`PrdInputForm`, `ReviewCard`, `LoadingSpinner`等の主要コンポーネントがPropsを受け取って正しく表示されることが確認できていること。
    -   [ ] 5.5 モックAPIに接続し、ページ実装と画面遷移を完成
        -   **Done:** Week1で作成したモックAPIを叩いて、各ページが意図通りに機能すること（画面遷移、データ表示、ローディング表示）がブラウザで確認できること。
-   [ ] **6. 統合とデプロイ**
    -   [ ] 6.1 フロントエンドの接続先を本実装APIに切り替え
        -   **Done:** フロントエンドが本物のバックエンドAPIを向いており、レビュー依頼から結果表示までの基本フローが動作すること。
    -   [ ] 6.2 自動デプロイ環境の構築
        -   **Done:** GitHubのmainブランチにマージされると、Vercel/Fly.io等へのデプロイが自動実行され、公開URLでアプリケーションが動作すること。

---

### **Week 3: 対話機能の作り込みとデモ準備**
**目標:** コア体験である「AIとの対話」をリッチにし、プロダクトの完成度を向上させる。最終デモに向けた準備を万端にする。

-   [ ] **7. フロントエンドの作り込み**
    -   [ ] 7.1 対話UI (`ChatWindow`) と `/dialog` APIの接続
        -   **Done:** チャットUIからメッセージを送信すると`/dialog` APIが呼ばれ、返ってきたレスポンスが画面に表示されること。
    -   [ ] 7.2 修正案の表示 (`SuggestionBox`) と `/suggest`, `/apply_suggestion` APIの接続
        -   **Done:** 各ボタンを押すと対応するAPIが呼ばれ、UIが適切に更新される（提案表示、トースト通知等）こと。
    -   [ ] 7.3 全体のデザイン改善
        -   **Done:** Figmaのデザインやチームで合意したスタイルガイドに沿って、UIが実装されていること。
    -   [ ] 7.4 エラーハンドリング強化
        -   **Done:** APIエラー時に、アプリケーションがクラッシュせず、ユーザーに適切なエラーメッセージが表示されること。
-   [ ] **8. AIバックエンドの改善**
    -   [ ] 8.1 プロンプトのチューニング
        -   **Done:** 複数パターンのPRDで動作確認し、指摘の質や形式に問題があれば`prompts.toml`を修正し、改善が見られることを確認する。
    -   [ ] 8.2 指摘の統合・優先順位付けロジックの改善
        -   **Done:** `structure_review_results`ツールのソートロジック等を見直し、より妥当な順序で指摘が表示されるようにコードを修正する。
-   [ ] **9. 最終デモ準備**
    -   [ ] 9.1 デモ用のPRDと発表シナリオの完成
        -   **Done:** デモで話す内容、見せる画面、操作する手順がドキュメント化されていること。
    -   [ ] 9.2 発表資料の作成
        -   **Done:** 発表用のスライドが完成していること。
    -   [ ] 9.3 チームでのデモリハーサル
        -   **Done:** チームメンバーの前でデモを一度通しで実施し、フィードバックを受けていること。
